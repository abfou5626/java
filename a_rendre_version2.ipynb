{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def initialisation_reseau_neurones(nbr_couches, taille_couches):\n",
    "    np.random.seed(1)  # Pour des r√©sultats reproductibles\n",
    "    \n",
    "    parameters = {}\n",
    "    \n",
    "    for l in range(1, nbr_couches):\n",
    "        parameters['W' + str(l)] = np.random.randn(taille_couches[l], taille_couches[l-1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((taille_couches[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_couches = 4\n",
    "taille_couches = [10, 20, 15, 5]  # Nombre de neurones dans chaque couche\n",
    "\n",
    "parametres = initialisation_reseau_neurones(nbr_couches, taille_couches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids (W1):\n",
      "[[ 0.01624345 -0.00611756 -0.00528172 -0.01072969  0.00865408 -0.02301539\n",
      "   0.01744812 -0.00761207  0.00319039 -0.0024937 ]\n",
      " [ 0.01462108 -0.02060141 -0.00322417 -0.00384054  0.01133769 -0.01099891\n",
      "  -0.00172428 -0.00877858  0.00042214  0.00582815]\n",
      " [-0.01100619  0.01144724  0.00901591  0.00502494  0.00900856 -0.00683728\n",
      "  -0.0012289  -0.00935769 -0.00267888  0.00530355]\n",
      " [-0.00691661 -0.00396754 -0.00687173 -0.00845206 -0.00671246 -0.00012665\n",
      "  -0.0111731   0.00234416  0.01659802  0.00742044]\n",
      " [-0.00191836 -0.00887629 -0.00747158  0.01692455  0.00050808 -0.00636996\n",
      "   0.00190915  0.02100255  0.00120159  0.00617203]\n",
      " [ 0.0030017  -0.0035225  -0.01142518 -0.00349343 -0.00208894  0.00586623\n",
      "   0.00838983  0.00931102  0.00285587  0.00885141]\n",
      " [-0.00754398  0.01252868  0.0051293  -0.00298093  0.00488518 -0.00075572\n",
      "   0.01131629  0.01519817  0.02185575 -0.01396496]\n",
      " [-0.01444114 -0.00504466  0.00160037  0.00876169  0.00315635 -0.02022201\n",
      "  -0.00306204  0.00827975  0.00230095  0.00762011]\n",
      " [-0.00222328 -0.00200758  0.00186561  0.00410052  0.001983    0.00119009\n",
      "  -0.00670662  0.00377564  0.00121821  0.01129484]\n",
      " [ 0.01198918  0.00185156 -0.00375285 -0.0063873   0.00423494  0.0007734\n",
      "  -0.00343854  0.00043597 -0.00620001  0.00698032]\n",
      " [-0.00447129  0.01224508  0.00403492  0.00593579 -0.01094912  0.00169382\n",
      "   0.00740556 -0.00953701 -0.00266219  0.00032615]\n",
      " [-0.01373117  0.00315159  0.00846161 -0.00859516  0.00350546 -0.01312283\n",
      "  -0.00038696 -0.01615772  0.01121418  0.00408901]\n",
      " [-0.00024617 -0.00775162  0.01273756  0.01967102 -0.01857982  0.01236164\n",
      "   0.01627651  0.00338012 -0.01199268  0.00863345]\n",
      " [-0.0018092  -0.00603921 -0.01230058  0.00550537  0.00792807 -0.00623531\n",
      "   0.00520576 -0.01144341  0.00801861  0.00046567]\n",
      " [-0.0018657  -0.00101746  0.00868886  0.00750412  0.00529465  0.00137701\n",
      "   0.00077821  0.0061838   0.00232495  0.00682551]\n",
      " [-0.00310117 -0.02434838  0.01038825  0.0218698   0.00441364 -0.00100155\n",
      "  -0.00136445 -0.00119054  0.00017409 -0.01122019]\n",
      " [-0.00517094 -0.00997027  0.00248799 -0.00296641  0.00495211 -0.00174703\n",
      "   0.00986335  0.00213534  0.021907   -0.01896361]\n",
      " [-0.00646917  0.00901487  0.02528326 -0.00248635  0.00043669 -0.00226314\n",
      "   0.01331457 -0.00287308  0.0068007  -0.00319802]\n",
      " [-0.01272559  0.00313548  0.00503185  0.01293226 -0.00110447 -0.00617362\n",
      "   0.00562761  0.00240737  0.00280665 -0.00073113]\n",
      " [ 0.01160339  0.00369493  0.01904659  0.01111057  0.0065905  -0.01627438\n",
      "   0.00602319  0.00420282  0.00810952  0.01044442]]\n",
      "Biais (b1):\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Poids (W2):\n",
      "[[-4.00878192e-03  8.24005618e-03 -5.62305431e-03  1.95487808e-02\n",
      "  -1.33195167e-02 -1.76068856e-02 -1.65072127e-02 -8.90555584e-03\n",
      "  -1.11911540e-02  1.95607890e-02 -3.26499498e-03 -1.34267579e-02\n",
      "   1.11438298e-02 -5.86523939e-03 -1.23685338e-02  8.75838928e-03\n",
      "   6.23362177e-03 -4.34956683e-03  1.40754000e-02  1.29101580e-03]\n",
      " [ 1.61694960e-02  5.02740882e-03  1.55880554e-02  1.09402696e-03\n",
      "  -1.21974440e-02  2.44936865e-02 -5.45774168e-03 -1.98837863e-03\n",
      "  -7.00398505e-03 -2.03394449e-03  2.42669441e-03  2.01830179e-03\n",
      "   6.61020288e-03  1.79215821e-02 -1.20464572e-03 -1.23312074e-02\n",
      "  -1.18231813e-02 -6.65754518e-03 -1.67419581e-02  8.25029824e-03]\n",
      " [-4.98213564e-03 -3.10984978e-03 -1.89148284e-05 -1.39662042e-02\n",
      "  -8.61316361e-03  6.74711526e-03  6.18539131e-03 -4.43171931e-03\n",
      "   1.81053491e-02 -1.30572692e-02 -3.44987210e-03 -2.30839743e-03\n",
      "  -2.79308500e-02  1.93752881e-02  3.66332015e-03 -1.04458938e-02\n",
      "   2.05117344e-02  5.85662000e-03  4.29526140e-03 -6.06998398e-03]\n",
      " [ 1.06222724e-03 -1.52568032e-02  7.95026094e-03 -3.74438319e-03\n",
      "   1.34048197e-03  1.20205486e-02  2.84748111e-03  2.62467445e-03\n",
      "   2.76499305e-03 -7.33271604e-03  8.36004719e-03  1.54335911e-02\n",
      "   7.58805660e-03  8.84908814e-03 -8.77281519e-03 -8.67787223e-03\n",
      "  -1.44087602e-02  1.23225307e-02 -2.54179868e-03  1.39984394e-02]\n",
      " [-7.81911683e-03 -4.37508983e-03  9.54250872e-04  9.21450069e-03\n",
      "   6.07501958e-04  2.11124755e-03  1.65275673e-04  1.77187720e-03\n",
      "  -1.11647002e-02  8.09271010e-04 -1.86578994e-03 -5.68244809e-04\n",
      "   4.92336556e-03 -6.80678141e-03 -8.45080274e-04 -2.97361883e-03\n",
      "   4.17302005e-03  7.84770651e-03 -9.55425262e-03  5.85910431e-03]\n",
      " [ 2.06578332e-02 -1.47115693e-02 -8.30171895e-03 -8.80577600e-03\n",
      "  -2.79097722e-03  1.62284909e-02  1.33526763e-04 -6.94693595e-03\n",
      "   6.21803504e-03 -5.99804531e-03  1.12341216e-02  3.05267040e-03\n",
      "   1.38877940e-02 -6.61344243e-03  3.03085711e-02  8.24584625e-03\n",
      "   6.54580153e-03 -5.11884476e-04 -7.25597119e-03 -8.67768678e-03]\n",
      " [-1.35977326e-03 -7.97269785e-03  2.82675712e-03 -8.26097432e-03\n",
      "   6.21082701e-03  9.56121704e-03 -7.05840507e-03  1.19268607e-02\n",
      "  -2.37941936e-03  1.15528789e-02  4.38166347e-03  1.12232832e-02\n",
      "  -9.97019796e-03 -1.06793987e-03  1.45142926e-02 -6.18036848e-03\n",
      "  -2.03720123e-02 -1.94258918e-02 -2.50644065e-02 -2.11416392e-02]\n",
      " [-4.11639163e-03  1.27852808e-02 -4.42229280e-03  3.23527354e-03\n",
      "  -1.09991490e-03  8.54894544e-05 -1.68198840e-03 -1.74180344e-03\n",
      "   4.61164100e-03 -1.17598267e-02  1.01012718e-02  9.20017933e-03\n",
      "  -1.95057341e-03  8.05393424e-03 -7.01344426e-03 -5.37223024e-03\n",
      "   1.56263850e-03 -1.90221025e-03 -4.48738033e-03 -6.72448039e-03]\n",
      " [-5.57494722e-03  9.39168744e-03 -1.94332341e-02  3.52494364e-03\n",
      "  -2.36436952e-03  7.27813500e-03  5.15073614e-03 -2.78253447e-02\n",
      "   5.84646610e-03  3.24274243e-03  2.18628366e-04 -4.68673816e-03\n",
      "   8.53281222e-03 -4.13029310e-03  1.83471763e-02  5.64382855e-03\n",
      "   2.13782807e-02 -7.85533997e-03 -1.75592564e-02  7.14789597e-03]\n",
      " [ 8.52704062e-03  3.53600971e-04 -1.53879325e-02 -4.47895185e-03\n",
      "   6.17985534e-03 -1.84176326e-03 -1.15985185e-03 -1.75458969e-03\n",
      "  -9.33914656e-03 -5.33020326e-03 -1.42655542e-02  1.76795995e-02\n",
      "  -4.75372875e-03  4.77610182e-03 -1.02188594e-02  7.94528240e-03\n",
      "  -1.87316098e-02  9.20615118e-03 -3.53679249e-04  2.11060505e-02]\n",
      " [-1.30653407e-02  7.63804802e-04  3.67231814e-03  1.23289919e-02\n",
      "  -4.22856961e-03  8.64644065e-04 -2.14246673e-02 -8.30168864e-03\n",
      "   4.51615951e-03  1.10417433e-02 -2.81736269e-03  2.05635552e-02\n",
      "   1.76024923e-02 -6.06524918e-04 -2.41350300e-02 -1.77756638e-02\n",
      "  -7.77858827e-03  1.11584111e-02  3.10272288e-03 -2.09424782e-02]\n",
      " [-2.28765829e-03  1.61336137e-02 -3.74804687e-03 -7.49969617e-03\n",
      "   2.05462410e-02  5.34095368e-04 -4.79157099e-03  3.50167159e-03\n",
      "   1.71647264e-04 -4.29142278e-03  1.20845633e-02  1.11570180e-02\n",
      "   8.40861558e-03 -1.02887218e-03  1.14690038e-02 -4.97025792e-04\n",
      "   4.66643267e-03  1.03368687e-02  8.08844360e-03  1.78975468e-02]\n",
      " [ 4.51284016e-03 -1.68405999e-02 -1.16017010e-02  1.35010682e-02\n",
      "  -3.31283170e-03  3.86539145e-03 -8.51455657e-03  1.00088142e-02\n",
      "  -3.84832249e-03  1.45810824e-02 -5.32234021e-03  1.11813340e-02\n",
      "   6.74396105e-03 -7.22391905e-03  1.09899633e-02 -9.01634490e-03\n",
      "  -8.22467189e-03  7.21711292e-03 -6.25342001e-03 -5.93843067e-03]\n",
      " [-3.43900709e-03 -1.00016919e-02  1.04499441e-02  6.08514698e-03\n",
      "  -6.93286967e-04 -1.08392067e-03  4.50155513e-03  1.76533510e-02\n",
      "   8.70969803e-03 -5.08457134e-03  7.77419205e-03 -1.18771172e-03\n",
      "  -1.98998184e-03  1.86647138e-02 -4.18937898e-03 -4.79184915e-03\n",
      "  -1.95210529e-02 -1.40232915e-02  4.51122939e-03 -6.94920901e-03]\n",
      " [ 5.15413802e-03 -1.11487105e-02 -7.67309826e-03  6.74570707e-03\n",
      "   1.46089238e-02  5.92472801e-03  1.19783084e-02  1.70459417e-02\n",
      "   1.04008915e-02 -9.18440038e-03 -1.05344713e-03  6.30195671e-03\n",
      "  -4.14846901e-03  4.51946037e-03 -1.57915629e-02 -8.28627979e-03\n",
      "   5.28879746e-03 -2.23708651e-02 -1.10771250e-02 -1.77183179e-04]]\n",
      "Biais (b2):\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Poids (W3):\n",
      "[[-0.01719394  0.00057121 -0.00799547 -0.00291595 -0.00258983  0.00189293\n",
      "  -0.00563789  0.00089686 -0.00601157  0.00556074  0.01693809  0.0019687\n",
      "   0.00169869 -0.01164008  0.00693366]\n",
      " [-0.00758067 -0.00808847  0.00557439  0.00181039  0.01107175  0.01442877\n",
      "  -0.00539682  0.00128377  0.01760415  0.00966539  0.00713049  0.01306206\n",
      "  -0.00604603  0.00636583  0.01409253]\n",
      " [ 0.01620912 -0.00806185 -0.00251674  0.00382715 -0.00288997 -0.00391816\n",
      "   0.00684001 -0.0035341  -0.01787913  0.00361847 -0.00424493 -0.00731531\n",
      "  -0.01565738  0.01013822 -0.02227113]\n",
      " [-0.01699334 -0.00275846  0.01228956  0.01309706 -0.01154983 -0.00177632\n",
      "  -0.01510456  0.01011207 -0.01476563 -0.00143196  0.01032984 -0.00222414\n",
      "   0.0147016  -0.00870008  0.0036919 ]\n",
      " [ 0.00853282 -0.00139712  0.01386314  0.0054813  -0.0163745   0.03958603\n",
      "   0.00648644  0.00107343 -0.01398813  0.00081768 -0.00459943  0.00644354\n",
      "   0.0037167   0.01853009  0.00142251]]\n",
      "Biais (b3):\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = initialisation_reseau_neurones(nbr_couches, taille_couches)\n",
    "\n",
    "for layer in range(1, nbr_couches):\n",
    "    print(f\"Poids (W{layer}):\")\n",
    "    print(parameters[f'W{layer}'])\n",
    "    print(f\"Biais (b{layer}):\")\n",
    "    print(parameters[f'b{layer}'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    \n",
    "    # Propagation pour les couches cach√©es (relu)\n",
    "    for l in range(1, len(parameters) // 2):\n",
    "        A_prev = A\n",
    "        W = parameters['W' + str(l)]\n",
    "        b = parameters['b' + str(l)]\n",
    "        \n",
    "        Z = np.dot(W, A_prev) + b\n",
    "        A = np.maximum(0, Z)  # Fonction d'activation : relu\n",
    "        \n",
    "        cache = (A_prev, W, b, Z)\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Propagation pour la couche de sortie (sigmoid)\n",
    "    W = parameters['W' + str(len(parameters) // 2)]\n",
    "    b = parameters['b' + str(len(parameters) // 2)]\n",
    "    \n",
    "    Z = np.dot(W, A) + b\n",
    "    A = 1 / (1 + np.exp(-Z))  # Fonction d'activation : sigmoid\n",
    "    \n",
    "    cache = (A, W, b, Z)\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return A, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(10, 100)  # Exemple de donn√©es d'entr√©e avec 10 √©chantillons et 100 caract√©ristiques\n",
    "parameters = initialisation_reseau_neurones(nbr_couches, taille_couches)\n",
    "\n",
    "A, caches = forward_propagation(X, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49999947, 0.5000063 , 0.50000182, 0.50000115, 0.50000092,\n",
       "        0.49999949, 0.49999965, 0.50000113, 0.50000079, 0.5000027 ,\n",
       "        0.50000064, 0.49999909, 0.49999459, 0.50000194, 0.49999871,\n",
       "        0.50000085, 0.50000085, 0.50000124, 0.49999662, 0.49999775,\n",
       "        0.49999878, 0.49999848, 0.49999755, 0.49999977, 0.49999817,\n",
       "        0.49999987, 0.4999985 , 0.49999814, 0.49999666, 0.4999988 ,\n",
       "        0.5000043 , 0.50000115, 0.49999494, 0.49999828, 0.49999887,\n",
       "        0.49999974, 0.50000152, 0.49999918, 0.4999978 , 0.49999895,\n",
       "        0.49999832, 0.50000202, 0.50000024, 0.49999641, 0.50000109,\n",
       "        0.4999998 , 0.50000543, 0.50000738, 0.50000345, 0.50000075,\n",
       "        0.49999975, 0.49999848, 0.5000007 , 0.49999929, 0.49999885,\n",
       "        0.49999607, 0.49999748, 0.49999621, 0.49999661, 0.50000048,\n",
       "        0.49999909, 0.4999974 , 0.4999982 , 0.50000175, 0.49999967,\n",
       "        0.50000119, 0.49999925, 0.49999926, 0.50000521, 0.50000508,\n",
       "        0.49999675, 0.50000174, 0.49999652, 0.49999764, 0.4999974 ,\n",
       "        0.49999895, 0.50000076, 0.5000032 , 0.49999761, 0.50000584,\n",
       "        0.4999987 , 0.49999995, 0.50000138, 0.50000071, 0.49999956,\n",
       "        0.49999871, 0.49999799, 0.50000125, 0.49999971, 0.50000031,\n",
       "        0.50000475, 0.49999705, 0.49999842, 0.50000612, 0.50000046,\n",
       "        0.49999803, 0.49999986, 0.50000236, 0.50000377, 0.50000088],\n",
       "       [0.49999971, 0.50001996, 0.5000038 , 0.50001862, 0.50000996,\n",
       "        0.50000414, 0.50000658, 0.50000867, 0.50000944, 0.50000569,\n",
       "        0.50001081, 0.50000114, 0.50001169, 0.50000847, 0.50001112,\n",
       "        0.5000057 , 0.50001705, 0.50000242, 0.50000183, 0.50002978,\n",
       "        0.50000131, 0.50000591, 0.50000127, 0.5000194 , 0.50000171,\n",
       "        0.50000948, 0.50001886, 0.50000876, 0.50001011, 0.50000783,\n",
       "        0.50000615, 0.50001723, 0.50001642, 0.50001138, 0.50002639,\n",
       "        0.50000443, 0.5000223 , 0.50000281, 0.50000679, 0.50000939,\n",
       "        0.50000517, 0.50002428, 0.50001236, 0.50002064, 0.50000708,\n",
       "        0.50001823, 0.50001242, 0.50002418, 0.50001185, 0.50000767,\n",
       "        0.50000408, 0.50001641, 0.50001351, 0.50000767, 0.50001223,\n",
       "        0.50001583, 0.50001534, 0.50001064, 0.50000876, 0.50000432,\n",
       "        0.50000547, 0.50000424, 0.50000792, 0.5000223 , 0.50000574,\n",
       "        0.50002297, 0.50000418, 0.50001299, 0.50001943, 0.50001471,\n",
       "        0.50002257, 0.50001086, 0.50000756, 0.50000709, 0.50000883,\n",
       "        0.50000885, 0.50000697, 0.50001196, 0.50001527, 0.50000471,\n",
       "        0.50001933, 0.50002494, 0.50001337, 0.50000769, 0.50001158,\n",
       "        0.50000126, 0.50001441, 0.50000767, 0.49999986, 0.50000121,\n",
       "        0.50001615, 0.50001889, 0.50000074, 0.50001963, 0.50000494,\n",
       "        0.50000482, 0.5000023 , 0.50001266, 0.50001013, 0.50001269],\n",
       "       [0.49999789, 0.49997865, 0.49999237, 0.49998904, 0.49999123,\n",
       "        0.49999603, 0.49999883, 0.49999436, 0.49999716, 0.49999716,\n",
       "        0.49998972, 0.49999588, 0.49999998, 0.4999925 , 0.49999108,\n",
       "        0.49999659, 0.49998866, 0.49999713, 0.5000002 , 0.49998195,\n",
       "        0.49999747, 0.49999618, 0.49999781, 0.49998724, 0.49999784,\n",
       "        0.49999082, 0.4999894 , 0.4999961 , 0.49999875, 0.49999347,\n",
       "        0.49999318, 0.49999366, 0.4999923 , 0.49999943, 0.49998246,\n",
       "        0.49999735, 0.49998574, 0.49999466, 0.49999599, 0.49999846,\n",
       "        0.50000033, 0.49998722, 0.49998685, 0.49998225, 0.49999169,\n",
       "        0.49998817, 0.49999595, 0.49998598, 0.49998992, 0.49999028,\n",
       "        0.49999581, 0.49998863, 0.49999158, 0.4999949 , 0.49999612,\n",
       "        0.49999858, 0.49999095, 0.49999348, 0.49999456, 0.49999532,\n",
       "        0.4999964 , 0.50000055, 0.49999658, 0.49998555, 0.49999329,\n",
       "        0.49999126, 0.49999837, 0.49999431, 0.49998295, 0.49999314,\n",
       "        0.49998805, 0.49999099, 0.49999573, 0.49999982, 0.49999225,\n",
       "        0.49999241, 0.49999333, 0.49999304, 0.49999006, 0.49999646,\n",
       "        0.4999906 , 0.49998784, 0.49999111, 0.49999406, 0.49999586,\n",
       "        0.50000073, 0.49999305, 0.49999686, 0.4999994 , 0.49999419,\n",
       "        0.49998472, 0.49998754, 0.49999704, 0.49998466, 0.49999631,\n",
       "        0.50000019, 0.49999428, 0.49999588, 0.49999382, 0.49998962],\n",
       "       [0.49999879, 0.50000374, 0.50000078, 0.50000199, 0.49999787,\n",
       "        0.49999865, 0.49999826, 0.50000011, 0.50000906, 0.50000378,\n",
       "        0.49999831, 0.49999655, 0.50000517, 0.5000002 , 0.5000046 ,\n",
       "        0.4999986 , 0.50000251, 0.49999959, 0.49999473, 0.49999886,\n",
       "        0.49999636, 0.49999944, 0.49999778, 0.4999964 , 0.49999642,\n",
       "        0.50000297, 0.49999696, 0.49999979, 0.50000464, 0.49999538,\n",
       "        0.50000694, 0.49999437, 0.50000205, 0.50000048, 0.49998708,\n",
       "        0.49999644, 0.49999367, 0.49999821, 0.50000252, 0.50000156,\n",
       "        0.49999987, 0.49999592, 0.49999944, 0.49999773, 0.50000006,\n",
       "        0.49999258, 0.50000873, 0.49999978, 0.50000143, 0.49999459,\n",
       "        0.5000026 , 0.49999613, 0.50000094, 0.49999625, 0.50000665,\n",
       "        0.50000178, 0.49999698, 0.50000284, 0.49999708, 0.49999807,\n",
       "        0.4999958 , 0.49999503, 0.49999466, 0.49999431, 0.50000015,\n",
       "        0.50000182, 0.49999992, 0.49999471, 0.49999932, 0.50000801,\n",
       "        0.49999789, 0.50000857, 0.50000173, 0.49999824, 0.49999692,\n",
       "        0.49999909, 0.49999874, 0.50000564, 0.49999414, 0.50000658,\n",
       "        0.49999644, 0.49998974, 0.49999679, 0.50000037, 0.49999881,\n",
       "        0.49999876, 0.50000264, 0.49999963, 0.49999902, 0.49999972,\n",
       "        0.50000076, 0.50000563, 0.49999716, 0.49999963, 0.49999899,\n",
       "        0.49999728, 0.50000006, 0.50000404, 0.50000203, 0.500001  ],\n",
       "       [0.50000148, 0.50001046, 0.50000109, 0.50001228, 0.50000656,\n",
       "        0.50000154, 0.50000978, 0.50001079, 0.50000885, 0.50000386,\n",
       "        0.50000806, 0.5000066 , 0.50001564, 0.50000905, 0.50000606,\n",
       "        0.50000388, 0.50001904, 0.50000297, 0.50000082, 0.50001628,\n",
       "        0.50000117, 0.49999794, 0.50000026, 0.50001825, 0.50000082,\n",
       "        0.50001097, 0.50001553, 0.50000933, 0.50001395, 0.50000017,\n",
       "        0.50001232, 0.50002471, 0.50000505, 0.50001189, 0.50001739,\n",
       "        0.50000892, 0.50001368, 0.49999858, 0.50000772, 0.50001298,\n",
       "        0.50000863, 0.50001413, 0.49999896, 0.50001027, 0.50000083,\n",
       "        0.50000485, 0.50000895, 0.50000956, 0.50000962, 0.50000842,\n",
       "        0.50000661, 0.50000017, 0.50001339, 0.50000452, 0.50002284,\n",
       "        0.50001645, 0.50001193, 0.50000669, 0.50000667, 0.50000786,\n",
       "        0.5000018 , 0.50000719, 0.50000433, 0.50001255, 0.500002  ,\n",
       "        0.50001156, 0.50000009, 0.50001454, 0.50001123, 0.50002161,\n",
       "        0.50001151, 0.500011  , 0.50001423, 0.50000783, 0.49999831,\n",
       "        0.49999871, 0.50000659, 0.50002345, 0.500016  , 0.50000131,\n",
       "        0.50000698, 0.50001507, 0.50001478, 0.50000934, 0.50001564,\n",
       "        0.50000271, 0.50001528, 0.5000108 , 0.50000316, 0.50000299,\n",
       "        0.50000472, 0.5000157 , 0.50000374, 0.50000625, 0.5000053 ,\n",
       "        0.50001053, 0.50000234, 0.5000065 , 0.50000264, 0.50000793]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caches\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def backward_propagation(X, Y, caches, parameters):\n",
    "\n",
    "    \n",
    "    m = X.shape[1]  # Nombre d'√©chantillons\n",
    "    \n",
    "    gradients = {}\n",
    "    dZ = None\n",
    "    \n",
    "    # R√©tropropagation pour la couche de sortie (sigmoid)\n",
    "    A = caches[-1][0]\n",
    "    dA = - (np.divide(Y, A) - np.divide(1 - Y, 1 - A))\n",
    "    dZ = dA * A * (1 - A)\n",
    "    \n",
    "    A_prev, W, b, Z = caches[-1]\n",
    "    dW = (1 / m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    gradients['dW' + str(len(caches))] = dW\n",
    "    gradients['db' + str(len(caches))] = db\n",
    "    \n",
    "    # R√©tropropagation pour les couches cach√©es (relu)\n",
    "    for l in reversed(range(len(caches) - 1)):\n",
    "        A_prev, W, b, Z = caches[l]\n",
    "        dZ = np.array(dA_prev, copy=True)\n",
    "        dZ[Z <= 0] = 0\n",
    "        \n",
    "        dW = (1 / m) * np.dot(dZ, A_prev.T)\n",
    "        db = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "        dA_prev = np.dot(W.T, dZ)\n",
    "        \n",
    "        gradients['dW' + str(l + 1)] = dW\n",
    "        gradients['db' + str(l + 1)] = db\n",
    "    \n",
    "    return gradients"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
